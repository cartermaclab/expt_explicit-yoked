---
title       : "Increased perceptions of autonomy through choice fail to enhance motor skill retention"
authors     : "Laura St. Germain, Allison Williams, Noura Balbaa, Andrew Poskus, Olena Leshchyshen, Keith R. Lohse & Michael J. Carter"
journal     : "Journal of Experimental Psychology: Human Perception and Performance"
manuscript  : "XHP-2021-1912"

class       : "final" # draft or final

output      : papaja::revision_letter_pdf
---

Jacqueline Clare Snow, PhD  
Associate Editor  
*Journal of Experimental Psychology: Human Perception and Performance*

Dear Dr. Snow,

Thank you for taking the time to consider our manuscript for publication at _`r rmarkdown::metadata$journal`_. We have read the comments provided by the Reviewers and have revised the manuscript accordingly. We thank the Reviewers for their helpful and insightful comments. Below we provide a point-by-point reply to the Reviewer comments (in bold-italic) and our responses in normal text. Any substantial changes that have been made to the original submission are also included in the response letter (in a text box) and are in red font in the revised manuscript.

Kind regards,

Laura St. Germain  
Allison Williams  
Noura Balbaa  
Andrew Poskus  
Olena Leshchyshen  
Keith R. Lohse  
Michael J. Carter


# Reviewer \#1

\RC{\emph{The authors provide a well-thought-out and clearly presented research design with clear theoretical implications. In particular, the analyses were very appropriate and should serve as an example for others conducting similar work. Though I carefully reviewed the manuscript, I do not have any specific suggested changes or questions for the authors. Though certainly not necessary for publication, the authors may wish consider the work of Katz and Assor (2007) surrounding choice and motivation from a Self Determination Theory perspective, as this seems to be relevant to the present findings. 
}}

Thank you for the positive comments about our manuscript and for sharing the reference to Katz and Assor (2007).

# Reviewer \#2

\RC{\emph{The authors submitted a well written manuscript reporting a pre-registered experiment that investigated the effect of awareness of being denied control over two relevant variables of the practice environment (i.e., frequency and speed of video demonstration) as participants learned the speed cup-stacking task. Results revealed that participants allowed to choose when to watch and the speed of the video demonstrations (i.e., self-controlled group) showed higher perceived autonomy scores when compared to yoked participants who received the demonstrations in matched schedule to a self-controlled counterpart and were either explicitly aware of this information (Explicit Yoked) or not (Traditional Yoked). However, the authors failed to replicate the so-called self-control learning benefit as no differences between groups were found in the retention test. Additionally, groups did not differ in self-reported measures of perceived competence and intrinsic motivation.}

\emph{Overall, I think this paper can be a valuable addition to the literature. The study is methodologically strong, it has one of the largest sample sizes reported in the motor learning literature, the authors pre-registered the main analyses, carried out a power calculation, and equivalence test, and heartfully embraced open science practices (I was able to easily reproduce the analyses/figures reported in the paper). However, I do have a few concerns/recommendations that, if addressed, can help to further improve the paper. 
}}

Thank your for the positive general comments about our manuscript. We are pleased to hear that you were able to reproduce the analyses and figures. Below are the responses to your specific comments. We have split the first comment into smaller chunks to facilitate our response.

\RC{\emph{My major concern is how the study's rationale and relevance are framed. The authors start by questioning the role played by autonomy support in practice conditions wherein provision of choice is manipulated. They argued that "if the benefits are the result of having opportunities for choice then learning differences should not emerge between different self-controlled groups" [Page 5, line 7]. However, this claim disregards another possible explanation for the self-control learning benefit, namely information processing factors (Barros et al., 2019).
}}

We agree with that an information-processing explanation has also been forwarded to account for the self-controlled learning advantages. We did not not specifically refer to it in the Introduction as this experiment was not designed to test between the motivational and the information-processing explanations. We have removed the quoted text in your comment in the revised submission and have added the following as a footnote to acknowledge the information-processing view (see Page 5):

> It should be noted that other researchers have instead presented an information-processing explanation for the self-controlled learning advantages (see Ste-Marie et al., 2019 for a recent discussion of the motivational and information-processing explanations). We acknowledge this view here; however, unlike previous experiments (e.g., Barros, Yantha, Carter, Hussien, & Ste-Marie, 2019; Carter, Carlsen, & Ste-Marie, 2014; Carter & Ste-Marie, 2017b, 2017a; Couvillion, Bass, & Fairbrother, 2020; Woodard & Fairbrother, 2020) the current experiment was not designed to test between explanations. We focused on the motivational explanation as this view has garnered more attention due the “OPTIMAL” theory of motor learning.

\RC{\emph{Second, they state that "there has been little-to-no support for the notion that practicing in a self-controlled group is perceived as more autonomy-supportive than being in a yoked group" [Page 5, line 15]. Although this statement has been supported by previous studies such as the one cited in the paper (Ste-Marie et al., 2013), group differences regarding levels of perceived autonomy have been found in recent studies (McKay \& Ste-Marie, 2020- also cited in the paper). The evidence, therefore, as presented in the paper seems mixed. Moreover, another explanation for the lack of group differences might have to do with the fact that increased levels of perceived autonomy have been assumed instead of directly measured in self-control studies. Thus, it becomes unclear whether the little-to-no support for the notion that practicing in a self-controlled group is perceived as more autonomy-supportive comes from a lack of differences when there is a measure of perceived autonomy or, rather, from a lack of studies assessing how provision of choice affects perception of autonomy. The authors then proceed to claim that "Although the available literature does not provide substantial evidence that self-controlled practice is autonomy-supportive, this does not necessarily mean such [extra 'a' here] manipulation is not autonomy-supportive. For instance, this effect may in fact be quite small and require much larger sample sizes to detect than those commonly used in motor learning experiments" [Page 5, line 25], which is a fair claim to make considering the methodological concerns surrounding motor learning studies (Lohse et al., 2016). However, the way this argument was structured led to the notion that it is still unclear whether self-control conditions lead to higher levels of perceived autonomy, circling back to my previous argument that the evidence is somewhat mixed and might be due to the lack of studies directly measuring perceived autonomy.
}}

We agree with many of the points raised here. We attempted to capture the mixed nature of findings by presenting experiments that failed to find an effect and the one that did find the expected effect. We restricted our discussion of past work not including measures in the Discussion as the true impact of this unknown and speculative. Based on your comments, we have restructured part of the Introduction to improve the clarity of our arguments (see Pages 5-6, Lines 5-20 and 1-9):

> Despite its prominent role as a robust and generalizable learning variable in the “OPTIMAL” theory (p. 1393), there is considerable ambiguity surrounding whether the provision of choice is in fact an autonomy-supportive manipulation. First, the notion that practicing in a self-controlled group is actually more autonomy-supportive than a yoked group has primarily been assumed (e.g., Abdollahipour, Palomo Nieto, Psotta, & Wulf, 2017; Chua, Wulf, & Lewthwaite, 2018; Lewthwaite, Chiviacowsky, Drews, & Wulf, 2015; Wulf, Lewthwaite, Cardozo, & Chiviacowsky, 2018) rather than supported empirically. Second, when researchers have included measures related to perceptions of autonomy the data is mixed. For example, Ste-Marie, Vertes, Law, and Rymal (2013) did not find the expected effect of higher perceptions of autonomy during practice in a self-controlled group as compared to a yoked group. Similar outcomes have been reported by others (e.g., Barros et al., 2019; Carter & Ste-Marie, 2017b; McKay & Ste-Marie, 2020a). In contrast, McKay and Ste-Marie (2020b) recently found that practicing in a self-controlled group was perceived as more autonomy-supportive than practicing the same task in a yoked group. However, despite their higher perceived autonomy scores the self-controlled group did not have significantly better motor performance and learning as predicted in the “OPTIMAL” theory. Although the majority of experiments that included a measure related to perceived autonomy reported no group differences, the “absence of evidence is not evidence of absence” (Altman & Bland, 1995). Thus, self-controlled practice conditions could be an autonomy-supportive manipulation but such an effect may actually be quite small and require much larger sample sizes to detect than those used in previous experiments (e.g., Barros et al., 2019; Ste-Marie et al., 2013) and in motor learning experiments in general (see Lohse, Buchanan, & Miller, 2016 for a discussion). This argument of underpowered experimental designs is supported by the results of McKay and Ste-Marie (2020b) as these authors had one of the largest sample sizes to date in the self-controlled literature.

\RC{\emph{Moreover, there was no explicit mention as to how levels of perceived autonomy might have a mechanistic role in motor skill learning. Self-control conditions might lead to higher levels of perceived autonomy but no learning advantage (as seen in the present study). But, when looking at the title of the paper and how the discussion unfolds, the authors shift their focus to claim that autonomy-support does not benefit motor learning.
}}

We agree that self-controlled practice conditions might lead to higher levels of perceived autonomy without any learning advantage. This, however, is not what is predicted in "OPTIMAL" theory where a causal relationship is put forward. The title of our paper and how the discussion unfolds is based on the results of our experiment, which suggests that increased perceptions of autonomy do not benefit motor learning. To your first point, we have added the following to the introduction to better outline how autonomy-support might have a mechanistic role in motor performance and learning according to the "OPTIMAL" theory of motor learning (see Pages 4-5, Lines 18-27 and 1-4):

> Within their “OPTIMAL” theory of motor learning, Wulf and Lewthwaite (2016) argued that providing learners with opportunities for choice creates an autonomy-supportive practice environment, which facilitates motor performance and learning. Specifically, the authors predict that autonomy-support facilitates performance by enhancing expectancies (Prediction 3, p. 1404), that enhanced expectancies and autonomy support contribute to efficient goal-action coupling by readying the motor system for task execution (Prediction 2, p. 1404), and that enhanced expectancies and autonomy support facilitate motor learning by making dopamine available for memory consolidation and neural pathway development (Prediction 7, p. 1404). In other words, these psychological benefits of increased perceptions of autonomy and competence, and the resulting increases in performance and learning are a by-product of having choice itself. Overall, Wulf and Lewthwaite (2016)’s “OPTIMAL” theory of motor learning provides a motivational explanation for the learning advantages of self-controlled practice conditions over yoked practice conditions.

\RC{\emph{The narrative in its current form lacks clarity. Are the authors interested in detecting group differences in levels of perceived autonomy (regardless of whether it predicts learning) or in the role of autonomy-support in enhancing learning (i.e., replicate the self-control learning benefit under a motivational perspective)? The issue gets even more cloudy as the authors raise two methodological concerns identified in the autonomy-support literature: 1) "The first of these is that in self-controlled motor learning experiments participants in the self-controlled group are usually given choice over a single component of their practice and participants inThank you for the positive comments about our manuscript the yoked group are not given choice over this component. However, within the context of practice itself there are many other opportunities for choice that participants may explore, independent of their assigned group" [Page6, line 4], and 2) "The other consideration relates to the instructions that are provided to participants in the yoked group [Page 6, line 16]", "Participants in yoked groups are not even aware that they have been denied an opportunity for choice, nor that their feedback schedule was created by another participant who was given choice over when feedback was or was not provided" [Page 6, line 20]. Regarding the first one, the benefits of self-control experiments have been found even when choice is given over an irrelevant aspect of the practice condition (incidental choice - Wulf \& Lewthwaite, 2016). Following this logic, it seems like the authors are referring specifically to the levels of perceived autonomy (having control over more variables might lead to higher levels of perceived autonomy). However, making yoked participants aware of being denied choice over some aspects of the practice condition does not prevent them from experiencing choice through other opportunities, weaking this argument. Moreover, this manipulation (i.e., making yoked participants aware of being denied choice) is better fitted under the controlling instructional language manipulation, which is contrasted against autonomy-supportive language (e.g., Hooyman et al., 2014). Yet, the authors do not even mention past research investigating the effect of controlling language on motor learning.
}}

Based on the "OPTIMAL" theory, we were interested in replicating the typical self-controlled learning advantage (group difference in retention favouring the self-controlled group) and testing the claim that self-controlled practice conditions are a way to create an autonomy-supportive environment (group difference in self-reported perceptions of autonomy). We have added details about our predictions to the revised manuscript (but we include this information below with your specific comment about these missing from the manuscript). In terms of the first methodological limitation, yes some researchers have reported a learning benefit of task-irrelevant choices (e.g., Lewthwaite & Wulf 2015; Wulf et al. 2017); however, this is a fairly selective stance given the mixed results surrounding task-irrelevant choices (e.g., Carter & Ste-Marie 2017; Grand et al. 2015; McKay & Ste-Marie 2020ab). Additionally, in McKay & Ste-Marie 2020a the task-irrelevant choice groups actually performed with significantly more error in acquisition and transfer than their yoked counterparts. As such, we respectfully disagree with your comment regarding the first methodoloThank you for the positive comments about our manuscriptgical limitation. Regarding the second methodological issue, we did not assert that making a yoked group aware that another participant created their observation schedule would prevent them from being able to experience other choice opportunities as we discuss in the Introduction. Instead, we outlined the methodological issues and acknowledged that "Either of these in isolation, or both simultaneously could contribute to the consistent finding that participants in self-controlled and yoked groups report similar perceived autonomy scores..." (Page 8, Lines 22-24 in original submission). We decided to only address the issue surrounding instructions with our manipulation as targeting all of the issues with the choice as autonomy-supportive literature would complicate our experimental design and likely contribute to an already messy and inconsistent body of literature as you have described in your review. 

Although the reviewer raises an interesting parallel with the controlling versus autonomy-supportive language manipulation, we respectfully disagree that our manipulation is better fitted under this area. In Hooyman et al. 2014, the controlling instructions are very specific and describe exactly how the learner must execute the task: 

"Your job today will be to learn a cricket pitch and perform it well. You may not begin throwing until you are told so. Make sure all of the tennis balls are in their respective holders. You may only remove one tennis ball at a time. Once you have been told when to commence throwing you must maintain a consistent pace. When initiating the approach of the pitch you must cradle the ball so it travels in a circular pattern. At the apex of the pitch the ball must be directly over the shoulder. Do not throw it at a side angle. When initiating the release you need to focus on the center of the target or the bounce area below the target" (Hooyman et al. 2014, p. 193).

Contrast this with our Explicit Yoked group instructions:

"Before each trial, you may or may not watch a modeled demonstration of the task based on the schedule another participant selected. If you observe a model, it might be presented in real-time or in slow-motion based on what that participant selected."

Compared to the instructions in Hooyman et al. 2014, our instructions are far more generic in terms of their upcoming practice environment and we make no statements regarding how the task must be executed. Instead, the denial of choice regarding the observation schedule is fairly subtle. Had we explicitly stated something along the lines of "This means you have been denied choice over your observation schedule" then we would agree such instructions would fit under the controlling language manipulation.

\RC{\emph{Overall, the introduction in its current form do not lead up to the research question nor does it highlight the relevance of the study. Are the authors manipulating autonomy support or autonomy restriction? It seems like the Explicit Yoked group is what makes this study unique (according to the authors), and yet little-to-no attention is given as to how the addition of this group can help to fill previously identified knowledge gaps in the self-control/autonomy support literature. I urge the authors to restructure the introduction in such way that the rationale, novelty, and relevance of the study are more evident.
}}

Our manipulations relate to choice (self-controlled or yoked) over observation schedule. As presented in our Introduction, it is far from clear whether such manipulations impact autonomy one way or the other. We have made changes throughout the introduction (as described above), but also have restructured the final paragraph of the Introduction based on your comments (see Pages 7-8, Lines 11-27, 1-8):

> Here, we addressed the methodological limitation of past self-controlled research where participants in the yoked group are unaware that a feature of their practice environment was created by another participant in the experiment. To this end, participants learned a speed cup-stacking task in either a self-controlled group, a traditional yoked group, or a novel explicitly aware yoked group. The self-controlled group has choice over the frequency of watching a video demonstration and the video playback speed (real-time or slow motion). Participants in the traditional and explicit yoked groups were matched to a participant in the self-controlled group and experienced the observation schedule selected by this participant. The key difference being that participants in the explicit yoked group were told that the observation schedule they would experience during practice was selected by another participant, whereas participants in the traditional yoked group were not aware of this. Motor learning was assessed using a delayed retention test. We predicted that the self-controlled group would have significantly faster stacking times in retention than the traditional yoked group. In other words, we expected to replicate the typical self-controlled learning advantage. If the self-controlled learning advantage results from choice being autonomy-supportive as argued in the “OPTIMAL” theory (Wulf & Lewthwaite, 2016), then participants in the self-controlled group should also self-report significantly higher scores for perceptions of autonomy. Also based on the view that autonomy-support is the mechanism underlying the typical self-controlled learning advantage (Wulf & Lewthwaite, 2016), we predicted that the explicit yoked group should have significantly slower stacking times in retention. Although we found significantly higher perceptions of autonomy in the self-controlled group, there were no significant group differences in stacking times during retention. Overall, these results do not support our predictions and are inconsistent with predictions 2, 3, and 7 in the “OPTIMAL” theory of motor learning (Wulf & Lewthwaite, 2016).

\RC{\emph{Still regarding the introduction, the authors did not mention their pre-registered hypotheses. Although they are available in the pre-registration form, it is important to include them in the manuscript. The inclusion of predicted outcomes, especially when they have been pre-registered, is crucial not only to help the reader to better understand the study's rationale, but also when we consider how studies might be used in the future. In the case of meta-analyses, for instance, studies may go through a quality assessment (that might include questions about the presence of previously established hypotheses) or be used in additional analyses such as the p-curve, in which researchers report a disclosure table where a number of questions need to be addressed, and one of them is specific to the presence/absence of clear hypotheses.
}}

We have fixed this oversight and included our predictions at the end of the Introduction as shown in the above response.

\RC{\emph{Page 5, line 2: "Overall, autonomy-support is seen as a mean [there is an extra 's' here] to efficient goal-action coupling (Wulf \& Lewthwaite, 2016) and also links the "OPTIMAL" theory with Self-Determination theory (Deci \& Ryan, 2000)." To aid a reader who might not be familiar the SDT, expand on how the OPTIMAL theory is linked to the SDT.
}}

Based on earlier comments, this text has been removed from the revised manuscript.

\RC{\emph{Although sample size calculation is somewhat specified in the pre-registration, it lacks important details that would allow the analysis to be replicated. Add a more detailed description of how sample size was calculated (e.g., software used and parameters adopted). 
}}

We have included the program used to conduct the sample size calculation. We did notice that alpha was not specifically mentioned in the manuscript for the sample size calculation, which we have fixed plus some minor edits (see Page 8, Line 21). However, we are unsure what additional parameters you expect for a more detailed description of how sample size was calculated.

\RC{\emph{Regarding the self-reported measures of perceived autonomy, intrinsic motivation, and perceived competence: report a measure of internal consistency for these questionnaires (e.g., Cronbach's alpha).
}}

We have added this information in a table (see Page 12).

\RC{\emph{The ratio of males and females was not reported. Again, when we consider the use of studies in meta-analytic approaches, one might want to carry out moderator analyses based on sex to make inferences about an effect, hence the importance of providing this type of information. 
}}

We have added this information (see Page 9, Lines 2-3).

\RC{\emph{Participants only requested to watch the demonstrations 16.7\% of the time on average. This seems a very small number and I wonder whether the authors thought about how this might have affected their results.
}}

While the mean frequency of observation (16.7%) is small relative to the frequency that feedback is typically requested (usually >60% when given choice after every trial), it is in line with previous research where participants had control of the frequency of modeled demonstrations: Wrisberg and Pein (2002) reported a frequency of 9.8% and Wulf, Raupach, & Pfeiffer (2005) reported a frequency of 5.8%. Given this, we do not think the requested frequency affected our results and importantly, frequency was controlled across groups.

\RC{\emph{Page 15, line 7: "To further probe the null effects (Harms \& Lakens, 2018) related to our main predictions". Here the authors allude to their predictions, but such predictions were not mentioned in the manuscript.
}}

We have added this information based on your earlier comment (see Pages 7-8, Lines 11-27, 1-8).

\RC{\emph{Page 21, line 26. "Given the resources required (in terms of sample size) to reliably detect these tiny effects, we encourage motor learning scientists to invest their limited resources carefully—either studying practice conditions that have much bigger effects or devising ways to reduce variability and increase power through clever experimental design". Include some examples on how future studies may design more clever and efficient experiments (e.g., the use of sequential analysis, collaboration between labs, etc.). 
}}

We have expanded this to include these suggestions (see Page 23, Lines 7-12).

\RC{\emph{It is interesting to see how the manipulation affected perceived autonomy but not levels of intrinsic motivation. In both Sanli et al. (2013) and Wulf and Lewthwaite (2016), the authors discuss how practice conditions in which one's perception of autonomy is supported lead to enhanced intrinsic motivation and, consequently, better motor learning. Did intrinsic motivation predict post-test performance regardless of group? If so, this finding would be consistent with the OPTIMAL theory's claim that motivation plays an important role in motor learning. Also, is it possible that the instrument used to index intrinsic motivation was not sensitive enough to capture changes in motivation levels? There is some research showing that different measures of motivation predict different aspects of a task (see Brunstein \& Schmitt, 2004). The authors briefly mention these findings in the discussion section but in a vague manner. For example: "Overall, our results are inconsistent with key predictions of the "OPTIMAL" theory regarding autonomy-support and enhanced expectancies…" [Page 21, line 7]. What predictions exactly? 
}}

The measured related to intrinsic motivation used in the present experiment is consistent with that used in previous experiments (e.g., Barros et al. 2019). While Sanli et al. (2013) and Wulf and Lewthwaite (2016) discuss how perceived autonomy through choice can enhance intrinsic motivation and better motor learning, Ste-Marie et al. (2015) ran a path analysis and showed that intrinsic motivation is not predictive of the self-controlled learning advantage. We elected to not run an exploratory analysis to test whether intrinsic motivation predicted post-test performance, regardless of group. We believe this not only detracts from the main question of our experiment, but there is not prediction in the "OPTIMAL" theory surrounding intrinsic motivation predicting post-test performance, independent of group. As mentioned in one of our earlier responses, we have made specific reference to the relevant predictions in the "OPTIMAL" theory (see Pages 4-5, Lines 18-27 and 1-4).

# Reviewer \#3

\RC{\emph{It was a pleasure to read and review your article "Increased perceptions of autonomy through choice fail to enhance motor skill retention" submitted to the Journal of Experimental Psychology: Human Perception and Performance. Your writing is apparent and concise. This article examines autonomy-support during the speed cup-stacking task. There were three conditions: the self-control group, the traditional yoked group, and the explicit yoked group. The results suggest that there are no statistically significant learning differences between the groups.
}}

Thank you for the positive comments about our manuscript.

\RC{\emph{Public significance statement, Lines 21-23, what kind of effective practice variable should coaches and practitioners use? Autonomy support affects skill learning among various populations. For instance: (https://www.tandfonline.com/doi/abs/10.1080/17461391.2020.1720829)
}}

Based on your comment and some reflection/discussions among ourselves, we decided to modify our public significance statement to the following:

> The present study suggests that although university-aged students may experience a boost in feelings of autonomy when given choice over features of their learning environment, this boost may not enhance learning of a new motor skill. Our results also highlight the need for higher powered and pre-registered motor learning experiments if coaches and practictioners are to be provided with reliable recommendations for training and rehabilitation protocols.

\RC{\emph{Equivalence tests? Why is it important? I have little experience with equivalence tests.
}}

When a null hypothesis significance test returns a non-significant result, many researchers incorrectly conclude that there is no effect or that groups are not different. Equivalence tests provide a statistical tool that researchers can use to support the absence of a meaningful effect. In other words, an equivalence test can help researchers conclude that a non-zero difference between groups is practically equivalent to zero.

\RC{\emph{Page 4, lines 17-20, does autonomy support differ between adults and children? Can you explain the findings of this study?
}}

The reference here is to the paper that introduces the "OPTIMAL" theory of motor learning, which argues that the learning benefits of self-controlled practice conditions are "very robust and generalizable to different tasks, age groups, and populations (p. 1393).

\RC{\emph{Lines 23-24 review the sentence.
}}

This sentence has been removed in the revised manuscript based on comments from Reviewer 2.

\RC{\emph{In lines 25-27 you mention previous literature does not indicate that self-controlled practice is autonomy-supportive, but in lines 17-18, p.4, you say a variety of names and labeled them as autonomy-supportive. Could you clarify this?
}}

We have updated our wording in these lines to clarify our position as our intention was not to label these names as being autonomy-supportive. This part now reads as (see Page 4, Lines 16-21):

> Over the years, this manipulation has been described using a variety of names (e.g., self- and/or learner-controlled; -regulated; -directed; -selected), but more recently some researchers have adopted the term autonomy-support. Within their “OPTIMAL” theory of motor learning, Wulf and Lewthwaite (2016) argued that providing learners with opportunities for choice creates an autonomy-supportive practice environment, which facilitates motor performance and learning.

\RC{\emph{ What was your hypothesis or prediction? Did your results support the hypothesis?
}}

We have added this information (see Pages 7-8, Lines 22-27 and 1-7):

> We predicted that the self-controlled group would have significantly faster stacking times in retention than the traditional yoked group. In other words, we expected to replicate the typical self-controlled learning advantage. If the self-controlled learning advantage results from choice being autonomy-supportive as argued in the “OPTIMAL” theory (Wulf & Lewthwaite, 2016), then participants in the self-controlled group should also self-report significantly higher scores for perceptions of autonomy. Also based on the view that autonomy-support is the mechanism underlying the typical self-controlled learning advantage (Wulf & Lewthwaite, 2016), we predicted that the explicit yoked group should have significantly slower stacking times in retention. Although we found significantly higher perceptions of autonomy in the self-controlled group, there were no significant group differences in stacking times during retention. Overall, these results do not support our predictions and are inconsistent with predictions 2, 3, and 7 in the “OPTIMAL” theory of motor learning (Wulf & Lewthwaite, 2016).

\RC{\emph{Thank you for providing additional material at asPredicted.org, it was very beneficial.
}}

You're welcome.

\RC{\emph{Lines 18-19, p.7, what age are the participants? Where were they recruited from? Who are we looking at? (e.g., university students, adults, etc.)?
}}

We have made specific reference that the participants were university students at the start of the Participants section (see Page 8, Line 15). It seems like the reported mean age of the participants in each group was missed. This information is also reported in the Participants section.

\RC{\emph{There was only one analysis explained, it would help if you discussed all analyses. Explain the analysis you ran in your data analysis section. 
}}

We described all analyses in the Results section as a way to reduce the cognitive load placed on the reader. We believe this prevents the reader from having to either remember all statistical analyses by the time they reach the Results section or having to scroll back and forth between the Data analysis section and the Results section. We have added a line to the Data analysis section that informs the reader that statistical tests are described below (see Page 12, Line 9).

\RC{\emph{Why do you have other graphs? You did not run an analysis on each trial but ran three by five.
}}

We have additional figures for transparency and for the interested reader. Figures 1A and 1D further support the pattern of results in Figures 1B and 1C and the associated outcomes of the statistical tests.

\RC{\emph{p.12, figure 1C, adjusted time is not explained in the results; what is adjusted mean stacking? Some of the graphs can be removed from the paper.
}}

Adjusted mean stacking time is stacking time in the retention test, adjusted for pre-test scores. We think our explanation for this may have been missed. In the Results section, we stated that "means are shown as the adjusted means controlling for pre-test" and the figure caption for 1C is "Mean stacking time (s) adjusted for pre-test for each group". We have elected to not removed any figures based on our response in the above comment.

\RC{\emph{Lines 10-17, p.13, please indicate the figure the reader should reference with your results. What graph is to be looked at when you ran your analysis? 
}}

We think our reference to which figures to look may have been overlooked as these were included in the relevant subsections of the Results section.

\RC{\emph{p.13, why did you use a Welch's t-test to compare two groups? Why not run a Welch's ANOVA between the three experimental groups? You had three experimental groups but only analyzed two, why?
}}

The analysis involving all three groups was run in our pre-registered analysis. As mentioned in the subsection Traditional self-controlled learning advantage, testing for a the typical self-controlled learning advantage involves a comparison between the Self-Controlled group and the Traditional Yoked group. This is why a Welch's t-test was used to test for this non-preregistered analysis. 

\RC{\emph{p.16, figure 2, I don't understand why you did this instead of bar graphs. To highlight group differences, why not use bar graphs instead of having every single data point on it. If no self-control effect was found, how can we trust the questionnaire data? 
}}

Bar graphs have been criticized as many different datasets can produce the same bar graph (see Figure 1 in Weissgerber et al. 2015, https://doi.org/10.1371/journal.pbio.1002128). For this reason, we show the individual data points in addition to the group mean for greater transparency.

This is a reasonable question; however, we are not sure a self-controlled learning advantage is required to trust questionnaire data. Despite the claim that the provision of choice is a very robust and generalizable learning variable in the "OPTIMAL" theory, the recent meta-analysis of the self-controlled literature we highlight in the discussion strongly challenges this assertion (McKay et al. Accepted). Thus, the provision of choice may only exert an influence on perceptions of autonomy (if you have a large enough sample size to detect this small effect), which in itself may be a desired outcome in some situations.

\RC{\emph{Can you explain why you have pre-registered and registered analyses separate? Why is a one-way ANCOVA the only pre-registered analysis?
}}

The ANCOVA is our only pre-registered analysis as this was our first time doing a pre-registration and we overlooked specifying the other analyses typically run in a self-controlled motor learning experiment. It is for this reason, we separated our analyses into a Pre-registered analysis and Non pre-registered analyses to be transparent that only one analysis was pre-registered.

\RC{\emph{Can you address the equivalence tests? Most motor learning researchers are not familiar with these tests, why are equivalence tests used and needed in this study? 
}}

We have added a description for why we included equivalance tests in the present experiment (see Page 16, Lines 7-13):

> Given our pre-registered analysis resulted in a non-significant finding, we performed two equivalence tests (Self-Controlled versus Traditional Yoked and Traditional Yoked versus Explicit Yoked) on pre-test adjusted retention stacking times using the two one-sided test procedure (Lakens et al., 2018; Schuirmann, 1987). Equivalence tests are a statistical tool that researchers can use to support the absence of a meaningful effect and avoid incorrectly concluded no effect exists based on a non-significant finding (Harms & Lakens, 2018).


\RC{\emph{How many papers use cup stacking? How do you know that it is not the task itself? Could the issue be with the task you chose? Why not use a task that is commonly used in motor learning? Is it an issue with the task, or is it an issue with the manipulation?
In summary, this research is interesting and well done. When major revisions are addressed, the authors should take advantage of the interesting information available to them and try to publish this work.
}}

We did a quick google scholar search for "motor learning cup stacking", which resulted in over 6500 papers. This is in line with our perception that cup-stacking is a commonly used task in motor learning research. Thus, we do not think a task argument is valid for the lack of a self-controlled learning advantage. We think the underlying issue is that the view within the "OPTIMAL" theory that self-controlled practice conditions are a very robust and generalizable learning variable is simply wrong as supported by the trivial effects found in the meta-analysis by McKay and colleagues. As mentioned in the Discussion section, our estimated effect for self-controlled versus yoked fell within the plausible range of these trivial effects.


<!-- \clearpage -->

<!-- # References -->

<!-- \begingroup -->

<!-- <div id="refs"></div> -->

<!-- \endgroup -->
